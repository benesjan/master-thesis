\chapter{Convolutional Neural Networks}\label{ch:cnn}
Convolutional Neural Networks (CNNs) are a group of models which allow for efficient training on high dimensional data.
This is especially useful in the field of computer vision as image data is fundamentally high dimensional.

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{images/cnn/lenet.eps}
    \caption{Example of CNN model (LeNet 5)~\cite{CNN}}
    \label{fig:cnn}
\end{figure}

The image~\ref{fig:cnn} is an illustration of one of the oldest CNN models \textit{LenNet 5} which was used for
handwritten character recognition.
As we can see, there are many layers stacked in the model's architecture.
This is typical for CNNs and it's a reason why CNNs belong to the class of machine learning methods called
\textit{deep learning}\footnote{Set of machine learning models with
\textit{credit assignment path (CAP)} higher than 2.
The CAP is the chain of transformations from input to output.}
Usually there are three layer types in the CNN model: \textit{dense}~\ref{sec:dense},
\textit{convolutional}~\ref{sec:convolutional} and \textit{pooling}~\ref{sec:pooling}.

\section{Dense layer}\label{sec:dense}
Dense layer is the simplest type of layer present in CNN models.
Its output is determined simply by multiplication of \textit{inputs} (x) with \textit{weight matrix}
(denoted V in~\ref{eq:dense}) and addition of \textit{bias} (u).

\begin{equation}\label{eq:dense}
    h[i, j] = u[i,j] + \sum_{a,b} V[i,j,a,b] \cdot x[i+a,j+b]
\end{equation}

Now let's imagine, that we have greyscale image which is 256 pixel wide and high as an input.
If we flatten the image to a vector, we get input with $256\cdot256 = 65536$ dimensions.
Even if we do aggressive reduction to 1000 hidden dimensions, we end up with ~65 million parameters.
This makes dense layer impractical when dealing with imagery and that's when convolution~\ref{sec:convolutional} comes
into play.

\section{Convolutional layer}\label{sec:convolutional}
As I hinted in the previous section, the main objective of convolutional layer is to decrease the amount of parameters
needed.
This feat was achieved by application of two principles: \textit{invariance}~\ref{subsec:invariance} and
\textit{locality}~\ref{subsec:locality}.

\subsection{Invariance principle}\label{subsec:invariance}
The core of invariance principle is reuse of the weights.
This is achieved by application of the weights on one part of the image, moving the weights by predetermined set
of pixels (called stride) and then applying the weights again.
We can have a look at equation~\ref{eq:denseinv} too see how the original equation~\ref{eq:dense} changes.

\begin{equation}\label{eq:denseinv}
h[i, j] = u + \sum_{a,b} V[a,b] \cdot x[i+a,j+b]
\end{equation}

As is to be expected, bias \textit{u} and the weight matrix \textit{V} are no longer dependent upon the image
coordinates \textit{(i, j)}.
As an example we can think of an airplane detection algorithm whose objective is to find where in the scene is an
airplane.
We would do that by sliding one set of weights describing the airplane over the image.
The algorithm would classify scene location with high impulse response as a location of the airplane.
This intuitively makes a lot of sense.

\subsection{Locality principle}\label{subsec:locality}

\section{Pooling layer}\label{sec:pooling}

